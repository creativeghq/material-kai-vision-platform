+++
id = "TASK-PY-20250831-051700"
title = "Add TogetherAI/LLaMA Vision Integration to MIVAA Python Microservice"
status = "üü° In Progress"
type = "üåü Feature"
assigned_to = "dev-python"
coordinator = "TASK-ARCH-20250830-172000"
priority = "high"
estimated_effort = "medium"
created_date = "2025-08-31T05:17:00Z"
updated_date = "2025-08-31T06:52:18Z"
related_docs = [
    "mivaa-pdf-extractor/requirements.txt",
    "mivaa-pdf-extractor/app/services/",
    "src/config/together-ai.config.ts",
    "supabase/functions/visual-search/index.ts"
]
tags = ["mivaa", "together-ai", "llama-vision", "python", "ai-integration"]
dependencies = []
blocking = ["TASK-ARCH-20250830-172000"]
+++

# Add TogetherAI/LLaMA Vision Integration to MIVAA Python Microservice

## Description

Critical integration task: Add TogetherAI + LLaMA Vision capabilities to the MIVAA Python microservice to complete the AI service stack required for centralizing all AI operations through MIVAA API.

**Context:** MIVAA currently supports OpenAI, HuggingFace, and CLIP embeddings but lacks TogetherAI integration. The main app's visual search pipeline requires LLaMA 3.2 Vision through TogetherAI API for semantic analysis (currently implemented directly in [`supabase/functions/visual-search/index.ts`](supabase/functions/visual-search/index.ts) lines 650-699).

**Goal:** Enable MIVAA to handle TogetherAI/LLaMA Vision requests so we can remove direct AI integrations from the main app and Supabase functions.

## Acceptance Criteria

- [ ] TogetherAI dependencies added to MIVAA requirements.txt
- [ ] TogetherAI service wrapper created with LLaMA Vision support
- [ ] API endpoints added for semantic analysis using LLaMA Vision
- [ ] Configuration management for TogetherAI API keys and models
- [ ] Error handling and rate limiting implemented
- [ ] Integration tested with exact model: `meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo`
- [ ] MIVAA gateway updated to route TogetherAI requests
- [ ] No regression in existing MIVAA functionality

## Technical Requirements

**Required TogetherAI Integration:**
- Model: `meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo`
- API Endpoint: `https://api.together.xyz/v1/chat/completions`
- Functionality: Material image semantic analysis (matching current visual-search implementation)

**Reference Implementation:**
- Source: [`supabase/functions/visual-search/index.ts`](supabase/functions/visual-search/index.ts) lines 650-699 `generateSemanticDescription()`
- Configuration pattern: [`src/config/together-ai.config.ts`](src/config/together-ai.config.ts)

**Integration Points:**
- Add to existing MIVAA service architecture in [`mivaa-pdf-extractor/app/services/`](mivaa-pdf-extractor/app/services/)
- Follow patterns established by [`embedding_service.py`](mivaa-pdf-extractor/app/services/embedding_service.py) and [`llamaindex_service.py`](mivaa-pdf-extractor/app/services/llamaindex_service.py)

## Checklist

### Phase 1: Dependencies & Setup üîß
- [ ] Add TogetherAI HTTP client dependencies to [`requirements.txt`](mivaa-pdf-extractor/requirements.txt)
- [ ] Update MIVAA configuration to support TogetherAI API keys
- [ ] Create environment variable configuration for TogetherAI settings

### Phase 2: Service Implementation üõ†Ô∏è
- [‚úÖ] Create `together_ai_service.py` in [`mivaa-pdf-extractor/app/services/`](mivaa-pdf-extractor/app/services/)
- [‚úÖ] Implement TogetherAI client wrapper with rate limiting and error handling
- [‚úÖ] Add LLaMA Vision image analysis functionality matching current implementation
- [‚úÖ] Implement semantic description generation for material analysis

### Phase 3: API Integration üåê
- [‚úÖ] Add TogetherAI endpoints to MIVAA FastAPI application
- [‚úÖ] Create `/api/semantic-analysis` endpoint for LLaMA Vision
- [‚úÖ] Update main MIVAA router to include TogetherAI routes
- [ ] Add action mapping in [`src/api/mivaa-gateway.ts`](src/api/mivaa-gateway.ts)

### Phase 4: Testing & Validation ‚úÖ
- [ ] Test TogetherAI service independently  
- [ ] Test semantic analysis endpoint with sample material images
- [ ] Validate exact model `meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo` functionality
- [ ] Verify integration with existing MIVAA services
- [ ] Test through main app MIVAA gateway

## Technical Notes

**Environment Variables to Add:**
```
TOGETHER_API_KEY=your_together_ai_api_key
TOGETHER_MODEL=meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo
TOGETHER_MAX_TOKENS=4096
TOGETHER_TEMPERATURE=0.1
TOGETHER_TIMEOUT=60
```

**Expected API Interface:**
```
POST /api/semantic-analysis
{
  "image_data": "base64_or_url",
  "analysis_type": "material_identification",
  "prompt": "Analyze this material image...",
  "options": {
    "temperature": 0.1,
    "max_tokens": 200
  }
}
```

**Response Format:**
```
{
  "analysis": "Generated semantic description",
  "confidence": 0.95,
  "model_used": "meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo",
  "processing_time_ms": 1500
}
```

## Risk Assessment

**Low Risk:** Adding new service to existing MIVAA architecture without modifying existing functionality.

**Mitigation:** Follow established MIVAA patterns and test thoroughly before integration with main app.

## Expected Outcome

MIVAA Python microservice will support complete AI service stack (OpenAI + HuggingFace + CLIP + TogetherAI), enabling removal of direct AI integrations from main app and Supabase functions while preserving all functionality.