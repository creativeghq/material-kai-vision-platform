# AI Models Architecture - Complete Overview

## ğŸ¯ Executive Summary

MIVAA Platform uses **8 different AI models** across **4 providers** for different purposes:

| Provider | Models Used | Primary Purpose |
|----------|-------------|-----------------|
| **Google** | SigLIP ViT-SO400M | Visual embeddings (512D) |
| **OpenAI** | text-embedding-3-small, GPT-4o, GPT-5 | Text embeddings, chat, product discovery |
| **Anthropic** | Claude Sonnet 4.5, Claude Haiku 4.5 | Vision analysis, validation, agents |
| **TogetherAI** | Llama 4 Scout 17B Vision | Image analysis, OCR, material detection |

---

## ğŸ“Š Complete Model Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PDF UPLOAD & PROCESSING                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 1: Product Discovery (BEFORE extraction)                          â”‚
â”‚ Model: Claude Sonnet 4.5 OR GPT-5                                      â”‚
â”‚ Purpose: Identify products, count pages, map image-to-product          â”‚
â”‚ Input: PDF pages (images)                                              â”‚
â”‚ Output: Product list with page ranges                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 2: Image Extraction & OCR Filtering                              â”‚
â”‚ Model: SigLIP ViT-SO400M                                               â”‚
â”‚ Purpose: Filter images - only OCR technical specs, skip lifestyle      â”‚
â”‚ Input: Extracted images                                                â”‚
â”‚ Output: Filtered images for OCR processing                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 3: Image Analysis (Primary)                                      â”‚
â”‚ Model: Llama 4 Scout 17B Vision (TogetherAI)                          â”‚
â”‚ Purpose: Detailed material analysis, color detection, texture          â”‚
â”‚ Input: Product images                                                  â”‚
â”‚ Output: Material properties, colors, textures, quality scores          â”‚
â”‚ Why: 69.4% MMMU score, #1 OCR performance, cost-effective             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 4: Image Analysis (Validation - Optional)                        â”‚
â”‚ Model: Claude 4.5 Sonnet Vision                                       â”‚
â”‚ Purpose: Validate low-quality Llama results, enrich metadata          â”‚
â”‚ Input: Images with quality_score < 0.7                                â”‚
â”‚ Output: Enhanced analysis, validation                                  â”‚
â”‚ Why: Higher accuracy, better reasoning, used only when needed         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 5: Visual Embeddings (5 types)                                   â”‚
â”‚ Model: SigLIP ViT-SO400M (Google)                                     â”‚
â”‚ Purpose: Generate 5 specialized 512D embeddings per image             â”‚
â”‚ Types:                                                                 â”‚
â”‚   1. Visual (general appearance)                                       â”‚
â”‚   2. Color (color palette)                                            â”‚
â”‚   3. Texture (surface patterns)                                       â”‚
â”‚   4. Application (use-case)                                           â”‚
â”‚   5. Material (material type)                                         â”‚
â”‚ Why: +19-29% accuracy over CLIP, same 512D dimension                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ STAGE 6: Text Embeddings                                               â”‚
â”‚ Model: OpenAI text-embedding-3-small                                  â”‚
â”‚ Purpose: Generate 1536D embeddings for text chunks                    â”‚
â”‚ Input: Product descriptions, specifications, chunk text               â”‚
â”‚ Output: 1536D text embeddings                                         â”‚
â”‚ Why: Industry standard, high quality, cost-effective                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         STORAGE (Supabase)                              â”‚
â”‚ - Products table (metadata)                                            â”‚
â”‚ - Images table (5x 512D embeddings per image)                         â”‚
â”‚ - Chunks table (1536D text embeddings)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER SEARCH & AGENT QUERIES                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ SEARCH: Multimodal RAG (LlamaIndex)                                    â”‚
â”‚ Models:                                                                â”‚
â”‚   - Text Embeddings: OpenAI text-embedding-3-small (1536D)            â”‚
â”‚   - Visual Embeddings: CLIP ViT-B/32 (512D) - LlamaIndex native      â”‚
â”‚   - LLM: GPT-4o OR Claude Sonnet 4.5                                 â”‚
â”‚ Purpose: Retrieve relevant chunks/images, generate answers            â”‚
â”‚ Why: LlamaIndex handles multimodal RAG, CLIP for compatibility        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENTS: Mastra Framework (Agent Hub)                                   â”‚
â”‚ Models Available:                                                      â”‚
â”‚   - Claude Sonnet 4.5 (default for agents)                           â”‚
â”‚   - Claude Haiku 4.5 (fast responses)                                â”‚
â”‚   - GPT-5 (advanced reasoning)                                        â”‚
â”‚   - Llama 4 Scout 17B (cost-effective)                               â”‚
â”‚ Purpose: Conversational AI, material search, recommendations          â”‚
â”‚ Why: Mastra provides agent orchestration, tool calling                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Detailed Model Breakdown

### 1. **Google SigLIP ViT-SO400M** ğŸ¯

**File**: `mivaa-pdf-extractor/app/services/real_embeddings_service.py`

**Usage**:
```python
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('google/siglip-so400m-patch14-384')
embedding = model.encode(pil_image, convert_to_numpy=True)
embedding = embedding / np.linalg.norm(embedding)  # L2 normalize
```

**Purpose**:
- Generate 512D visual embeddings for images
- 5 specialized embeddings per image (visual, color, texture, application, material)
- OCR filtering (classify images as technical vs lifestyle)

**Impact on Flow**:
- âœ… **PDF Processing**: Filters images before OCR (saves processing time)
- âœ… **Embedding Generation**: Creates all 5 visual embeddings (Stage 7-10, 80-91%)
- âœ… **Search**: Enables visual similarity search
- âœ… **Accuracy**: +19-29% improvement over CLIP

**Cost**: Free (Hugging Face)  
**Speed**: 150-400ms per image  
**Output**: 512D numpy array â†’ normalized â†’ list

---

### 2. **OpenAI text-embedding-3-small** ğŸ“

**File**: `mivaa-pdf-extractor/app/services/real_embeddings_service.py`

**Usage**:
```python
response = await client.post(
    "https://api.openai.com/v1/embeddings",
    json={"input": text, "model": "text-embedding-3-small"}
)
embedding = response.json()["data"][0]["embedding"]  # 1536D
```

**Purpose**:
- Generate 1536D text embeddings for chunks
- Text-based semantic search
- Multimodal search (combine with visual)

**Impact on Flow**:
- âœ… **PDF Processing**: Embeds all text chunks (Stage 5, 60-70%)
- âœ… **Search**: Primary text search mechanism
- âœ… **RAG**: LlamaIndex uses for retrieval

**Cost**: $0.00002 per 1K tokens
**Speed**: 100-300ms
**Output**: 1536D list

---

### 3. **Llama 4 Scout 17B Vision** ğŸ¦™

**File**: `mivaa-pdf-extractor/app/services/real_image_analysis_service.py`

**Usage**:
```python
response = await client.post(
    "https://api.together.xyz/v1/chat/completions",
    json={
        "model": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "messages": [{"role": "user", "content": [
            {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}},
            {"type": "text", "text": analysis_prompt}
        ]}]
    }
)
```

**Purpose**:
- **Primary image analysis** for all product images
- Material identification, color detection, texture analysis
- Quality scoring, OCR text extraction
- Cost-effective vision model

**Impact on Flow**:
- âœ… **PDF Processing**: Analyzes ALL images (Stage 6, 70-80%)
- âœ… **Material Detection**: Identifies materials, colors, textures
- âœ… **Quality Scoring**: Scores image quality (0.0-1.0)
- âœ… **OCR**: Extracts text from technical diagrams
- âš ï¸ **Validation**: Low scores (<0.7) trigger Claude validation

**Why Llama**:
- 69.4% MMMU score (multimodal understanding)
- #1 OCR performance among open models
- Cost-effective ($0.18 per 1M tokens vs Claude $3.00)
- Fast inference (2-5 seconds)

**Cost**: $0.18 per 1M input tokens, $0.18 per 1M output tokens
**Speed**: 2-5 seconds per image
**Output**: JSON with material properties, colors, quality scores

---

### 4. **Claude 4.5 Sonnet Vision** ğŸ¨

**File**: `mivaa-pdf-extractor/app/services/real_image_analysis_service.py`

**Usage**:
```python
client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
response = client.messages.create(
    model="claude-sonnet-4-5",
    max_tokens=4096,
    messages=[{
        "role": "user",
        "content": [
            {"type": "image", "source": {"type": "base64", "media_type": "image/jpeg", "data": image_base64}},
            {"type": "text", "text": validation_prompt}
        ]
    }]
)
```

**Purpose**:
- **Validation** of low-quality Llama results
- **Enrichment** of metadata
- **Product Discovery** (alternative to GPT-5)
- **Agent responses** (Mastra framework)

**Impact on Flow**:
- âœ… **PDF Processing**: Validates images with quality_score < 0.7 (async job)
- âœ… **Product Discovery**: Identifies products BEFORE extraction (Stage 1)
- âœ… **Agents**: Powers conversational AI in Agent Hub
- âœ… **RAG**: Optional LLM for LlamaIndex queries

**Why Claude**:
- Superior reasoning and accuracy
- Better at complex material analysis
- Excellent vision capabilities
- Used selectively to control costs

**Cost**: $3.00 per 1M input tokens, $15.00 per 1M output tokens
**Speed**: 3-8 seconds per image
**Output**: JSON with enhanced analysis

---

### 5. **GPT-4o / GPT-5** ğŸ¤–

**Files**:
- `mivaa-pdf-extractor/app/services/product_discovery_service.py`
- `mivaa-pdf-extractor/app/services/llamaindex_service.py`

**Usage**:
```python
# Product Discovery
response = await client.post(
    "https://api.openai.com/v1/chat/completions",
    json={"model": "gpt-5", "messages": [...]}
)

# LlamaIndex RAG
from llama_index.llms.openai import OpenAI
llm = OpenAI(model="gpt-4o", temperature=0.1)
```

**Purpose**:
- **Product Discovery**: Alternative to Claude for identifying products
- **RAG**: Default LLM for LlamaIndex multimodal queries
- **Agent**: Available in Agent Hub for advanced reasoning

**Impact on Flow**:
- âœ… **PDF Processing**: Product discovery (Stage 1, optional)
- âœ… **Search**: Generates answers from retrieved chunks
- âœ… **Agents**: Available for user queries

**Cost**: GPT-4o: $2.50/$10.00 per 1M tokens, GPT-5: TBD
**Speed**: 2-6 seconds
**Output**: Text responses, JSON

---

### 6. **Claude Haiku 4.5** âš¡

**File**: `src/components/AI/AgentHub.tsx`

**Usage**:
```typescript
const response = await supabase.functions.invoke('agent-chat', {
  body: {
    model: 'anthropic/claude-haiku-4-20250514',
    messages: [...]
  }
});
```

**Purpose**:
- **Fast agent responses** in Agent Hub
- **Quick queries** that don't need Sonnet's power
- **Cost optimization** for simple tasks

**Impact on Flow**:
- âœ… **Agents**: Fast conversational responses
- âœ… **Simple queries**: Material lookups, basic questions

**Cost**: $0.25 per 1M input tokens, $1.25 per 1M output tokens
**Speed**: 1-3 seconds
**Output**: Text responses

---

### 7. **CLIP ViT-B/32** (LlamaIndex Only) ğŸ”—

**File**: `mivaa-pdf-extractor/app/services/llamaindex_service.py`

**Usage**:
```python
from llama_index.embeddings.clip import ClipEmbedding
image_embeddings = ClipEmbedding(model_name="ViT-B/32")
```

**Purpose**:
- **LlamaIndex multimodal RAG** (internal use only)
- **NOT used for PDF processing** (replaced by SigLIP)
- Kept for LlamaIndex compatibility

**Impact on Flow**:
- âœ… **Search**: LlamaIndex uses for image-text retrieval
- âŒ **PDF Processing**: NOT used (SigLIP replaced it)

**Why Keep It**:
- LlamaIndex has native CLIP integration
- Changing would break LlamaIndex's multimodal capabilities
- Only used during search, not processing

**Cost**: Free
**Speed**: 100-300ms
**Output**: 512D embeddings

---

### 8. **Stable Diffusion / FLUX** (3D Designer) ğŸ¨

**File**: `src/components/3D/Designer3DPage.tsx`

**Models**:
- Stable Diffusion XL Base 1.0
- FLUX-Schnell
- Interior Design models (Replicate)

**Purpose**:
- **3D material visualization**
- **Interior design generation**
- **Material texture generation**

**Impact on Flow**:
- âœ… **3D Designer**: Generates material visualizations
- âœ… **Moodboards**: Creates design concepts
- âŒ **PDF Processing**: Not used

**Cost**: Varies by provider
**Speed**: 5-30 seconds
**Output**: Generated images

---

## ğŸ”„ Model Selection Logic

### PDF Processing Pipeline

```
1. Product Discovery (Stage 1)
   â”œâ”€ Default: Claude Sonnet 4.5
   â””â”€ Alternative: GPT-5

2. OCR Filtering (Stage 2)
   â””â”€ SigLIP ViT-SO400M (only model)

3. Image Analysis (Stage 6)
   â”œâ”€ Primary: Llama 4 Scout 17B Vision (ALL images)
   â””â”€ Validation: Claude 4.5 Sonnet (quality_score < 0.7)

4. Visual Embeddings (Stage 7-10)
   â””â”€ SigLIP ViT-SO400M (only model)

5. Text Embeddings (Stage 5)
   â””â”€ OpenAI text-embedding-3-small (only model)
```

### Search & Agents

```
1. LlamaIndex RAG
   â”œâ”€ Text Embeddings: OpenAI text-embedding-3-small
   â”œâ”€ Visual Embeddings: CLIP ViT-B/32 (LlamaIndex native)
   â””â”€ LLM: GPT-4o (default) OR Claude Sonnet 4.5

2. Agent Hub (Mastra)
   â”œâ”€ Default: Claude Sonnet 4.5
   â”œâ”€ Fast: Claude Haiku 4.5
   â”œâ”€ Advanced: GPT-5
   â””â”€ Cost-effective: Llama 4 Scout 17B
```

---

## ğŸ’° Cost Impact Analysis

### Per PDF Processing (100 pages, 50 images)

| Model | Usage | Cost |
|-------|-------|------|
| **Claude Sonnet 4.5** | Product discovery (1 call) | ~$0.05 |
| **SigLIP** | OCR filtering (50 images) | $0.00 (free) |
| **Llama 4 Scout** | Image analysis (50 images) | ~$0.02 |
| **Claude Sonnet 4.5** | Validation (10 low-quality) | ~$0.15 |
| **SigLIP** | Visual embeddings (250 total) | $0.00 (free) |
| **OpenAI Embeddings** | Text chunks (500 chunks) | ~$0.01 |
| **TOTAL** | Per PDF | **~$0.23** |

### Per Search Query

| Model | Usage | Cost |
|-------|-------|------|
| **OpenAI Embeddings** | Query embedding | <$0.001 |
| **CLIP** | Image query (LlamaIndex) | $0.00 |
| **GPT-4o / Claude** | Answer generation | ~$0.01 |
| **TOTAL** | Per query | **~$0.01** |

---

## ğŸ¯ Why This Architecture?

### 1. **Cost Optimization**
- Llama 4 Scout for bulk image analysis (cheap)
- Claude only for validation (selective)
- SigLIP for embeddings (free)

### 2. **Quality Optimization**
- SigLIP: +19-29% accuracy over CLIP
- Claude: Best-in-class vision for validation
- Llama: 69.4% MMMU, excellent OCR

### 3. **Speed Optimization**
- Llama: Fast inference (2-5s)
- SigLIP: Fast embeddings (150-400ms)
- Parallel processing where possible

### 4. **Compatibility**
- LlamaIndex: Keep CLIP for native integration
- Mastra: Support multiple agent models
- OpenAI: Industry standard embeddings

---

## ğŸ“ˆ Performance Metrics

| Metric | Before (CLIP) | After (SigLIP) | Improvement |
|--------|---------------|----------------|-------------|
| **Visual Search Accuracy** | 70-75% | 89-94% | +19-29% |
| **Embedding Generation** | 100-300ms | 150-400ms | Acceptable |
| **Model Size** | 350MB | 1.5GB | Larger but worth it |
| **Cost** | $0.00 | $0.00 | Same (free) |

---

## ğŸ”® Future Considerations

1. **Regenerate Existing Embeddings**: Batch job to upgrade CLIP â†’ SigLIP
2. **Monitor Llama Quality**: Track validation rate (should be <20%)
3. **A/B Test Models**: Compare Claude vs GPT-5 for product discovery
4. **Add More Agents**: Expand Mastra agent capabilities

---

**Last Updated**: 2025-01-17
**Status**: âœ… Production Ready

